{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Uso de las primeras 10 capas de VGG16, aÃ±adiendo una CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rauly/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/rauly/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(72, 96, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 72, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 72, 96, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 72, 96, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 36, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 36, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 36, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 12, 256)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 12, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 12, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 12, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 3, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,10):\n",
    "    conv_base.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 72, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 72, 96, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 72, 96, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 36, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 36, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 36, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,735,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = conv_base.input\n",
    "out =conv_base.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 72, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 72, 96, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 72, 96, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 36, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 36, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 36, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,735,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model2 = Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "for layer in model2.layers:\n",
    "    cont = cont + 1\n",
    "    if (cont >= 8):\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 72, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 72, 96, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 72, 96, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 36, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 36, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 36, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,475,328\n",
      "Non-trainable params: 260,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying images to training, validation, and test directories\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "#Path where my dataset is stored\n",
    "base_dir = '/home/rauly/Documents/Augmentation/Glasses16/Thermal_Glasses16/Training_Sections'\n",
    "base_dir1 = '/home/rauly/Documents/Augmentation/Glasses16/Thermal_Glasses16/Testing_Sections'\n",
    "\n",
    "# Directories for our training,\n",
    "# validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir1, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 18, 24, 256)       1735488   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 12, 256)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 12, 256)        1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 27648)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                442384    \n",
      "=================================================================\n",
      "Total params: 2,178,896\n",
      "Trainable params: 1,918,224\n",
      "Non-trainable params: 260,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(model2)\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "#model.add(layers.Conv2D(256, (3, 3), activation='relu'))\n",
    "#model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(16, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import metrics\n",
    "import functools\n",
    "from functools import partial\n",
    "top2_acc = functools.partial(metrics.top_k_categorical_accuracy, k=2)\n",
    "top3_acc = functools.partial(metrics.top_k_categorical_accuracy, k=3)\n",
    "top2_acc.__name__ = 'top2_acc'\n",
    "top3_acc.__name__ = 'top3_acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile stage\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), #Decrease learning rate\n",
    "              metrics=['accuracy',top2_acc, top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1168 images belonging to 16 classes.\n",
      "Found 1184 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "#Using ImageDataGenerator to read images from directories\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        # This is the target directory\n",
    "        train_dir,\n",
    "        # All images will be resized to 150x150\n",
    "        target_size=(72, 96),\n",
    "        batch_size= 4, #20\n",
    "        color_mode='rgb',\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='categorical')\n",
    "        #save_to_dir='/home/rauly/Documents/Augmentation/Augmented_images2')\n",
    "        #save_prefix='perf',\n",
    "        #save_format='jpg')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(72, 96),\n",
    "        batch_size=74,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "292/292 [==============================] - 97s 334ms/step - loss: 0.1725 - acc: 0.9572 - top2_acc: 0.9752 - top3_acc: 0.9786 - top4_acc: 0.9803 - top5_acc: 0.9812 - val_loss: 0.5156 - val_acc: 0.8666 - val_top2_acc: 0.9350 - val_top3_acc: 0.9628 - val_top4_acc: 0.9797 - val_top5_acc: 0.9924\n",
      "Epoch 2/10\n",
      "292/292 [==============================] - 99s 338ms/step - loss: 3.6667e-04 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - top4_acc: 1.0000 - top5_acc: 1.0000 - val_loss: 0.0871 - val_acc: 0.9713 - val_top2_acc: 0.9932 - val_top3_acc: 0.9983 - val_top4_acc: 1.0000 - val_top5_acc: 1.0000\n",
      "Epoch 3/10\n",
      "292/292 [==============================] - 98s 337ms/step - loss: 8.3951e-06 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - top4_acc: 1.0000 - top5_acc: 1.0000 - val_loss: 0.0322 - val_acc: 0.9941 - val_top2_acc: 0.9941 - val_top3_acc: 0.9975 - val_top4_acc: 1.0000 - val_top5_acc: 1.0000\n",
      "Epoch 4/10\n",
      "292/292 [==============================] - 99s 337ms/step - loss: 1.2089e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - top4_acc: 1.0000 - top5_acc: 1.0000 - val_loss: 0.0250 - val_acc: 0.9924 - val_top2_acc: 0.9949 - val_top3_acc: 1.0000 - val_top4_acc: 1.0000 - val_top5_acc: 1.0000\n",
      "Epoch 5/10\n",
      "292/292 [==============================] - 98s 337ms/step - loss: 1.1977e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - top4_acc: 1.0000 - top5_acc: 1.0000 - val_loss: 0.0244 - val_acc: 0.9924 - val_top2_acc: 0.9949 - val_top3_acc: 0.9992 - val_top4_acc: 1.0000 - val_top5_acc: 1.0000\n",
      "Epoch 6/10\n",
      "292/292 [==============================] - 98s 336ms/step - loss: 1.1921e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - top4_acc: 1.0000 - top5_acc: 1.0000 - val_loss: 0.0211 - val_acc: 0.9949 - val_top2_acc: 0.9958 - val_top3_acc: 1.0000 - val_top4_acc: 1.0000 - val_top5_acc: 1.0000\n",
      "Epoch 7/10\n",
      "292/292 [==============================] - 98s 337ms/step - loss: 1.1941e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - top4_acc: 1.0000 - top5_acc: 1.0000 - val_loss: 0.0199 - val_acc: 0.9949 - val_top2_acc: 0.9958 - val_top3_acc: 1.0000 - val_top4_acc: 1.0000 - val_top5_acc: 1.0000\n",
      "Epoch 8/10\n",
      "292/292 [==============================] - 99s 337ms/step - loss: 1.1941e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - top4_acc: 1.0000 - top5_acc: 1.0000 - val_loss: 0.0232 - val_acc: 0.9924 - val_top2_acc: 0.9958 - val_top3_acc: 1.0000 - val_top4_acc: 1.0000 - val_top5_acc: 1.0000\n",
      "Epoch 9/10\n",
      "292/292 [==============================] - 99s 338ms/step - loss: 1.1921e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - top4_acc: 1.0000 - top5_acc: 1.0000 - val_loss: 0.0224 - val_acc: 0.9932 - val_top2_acc: 0.9958 - val_top3_acc: 1.0000 - val_top4_acc: 1.0000 - val_top5_acc: 1.0000\n",
      "Epoch 10/10\n",
      "292/292 [==============================] - 98s 335ms/step - loss: 1.1931e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - top4_acc: 1.0000 - top5_acc: 1.0000 - val_loss: 0.0221 - val_acc: 0.9941 - val_top2_acc: 0.9958 - val_top3_acc: 1.0000 - val_top4_acc: 1.0000 - val_top5_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Previously trained, but I have to restart the process because of kernel's issues\n",
    "#Fitting the model using a batch generator\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=292, #70\n",
    "      epochs= 10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=16,\n",
    "      workers=0,\n",
    "      max_queue_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retraining\n",
    "model = models.Sequential()\n",
    "model.add(model2)\n",
    "#model.add(layers.BatchNormalization())\n",
    "#model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(16, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compile stage\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), #Decrease learning rate\n",
    "              metrics=['accuracy',top2_acc, top3_acc, top4_acc, top5_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "292/292 [==============================] - 72s 247ms/step - loss: 0.2791 - acc: 0.9307 - top2_acc: 0.9580 - top3_acc: 0.9675\n",
      "Epoch 2/3\n",
      "292/292 [==============================] - 65s 222ms/step - loss: 2.2155e-04 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000\n",
      "Epoch 3/3\n",
      "292/292 [==============================] - 67s 231ms/step - loss: 1.5812e-06 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Fitting the model using a batch generator\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=292,\n",
    "      epochs=3,\n",
    "      workers=0,\n",
    "      max_queue_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1184 images belonging to 16 classes.\n",
      "test acc: 0.9569256752729416\n",
      "Testing time: 32.994813680648804\n",
      "Recognition rate top2:  0.9864864945411682\n",
      "Recognition rate top3:  0.9881756827235222\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(72, 96),\n",
    "        batch_size=74,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical')\n",
    "start_time = time.time()\n",
    "test_loss, test_acc, test_top2_acc, test_top3_acc = model.evaluate_generator(test_generator, steps=16, workers=0, max_queue_size=0)\n",
    "end_time = time.time()\n",
    "testing_time = end_time - start_time\n",
    "print('test acc:', test_acc)\n",
    "print('Testing time:', testing_time)\n",
    "print('Recognition rate top2: ', test_top2_acc)\n",
    "print('Recognition rate top3: ', test_top3_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02786724128433176"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_time / 1184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model with the Glasses Hat dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path where my dataset is stored\n",
    "base_dir2 = '/home/rauly/Documents/Augmentation/Glasses16/Thermal_GlassesHat16/Testing_Sections'\n",
    "# Directories for test splits\n",
    "test_dir1 = os.path.join(base_dir2, 'test148')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2368 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "#Using ImageDataGenerator to read images from directories\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir1,\n",
    "    target_size=(72, 96),\n",
    "    batch_size=148,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition rate top1:  0.9493243247270584\n",
      "Recognition rate top2:  0.9687499962747097\n",
      "Recognition rate top3:  0.9805743210017681\n",
      "Recognition rate top4:  0.985219594091177\n",
      "Recognition rate top5:  0.9919763430953026\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_top2_acc, test_top3_acc, test_top4_acc, test_top5_acc = model.evaluate_generator(test_generator, steps=16, workers=0, max_queue_size=0)\n",
    "print('Recognition rate top1: ', test_acc)\n",
    "print('Recognition rate top2: ', test_top2_acc)\n",
    "print('Recognition rate top3: ', test_top3_acc)\n",
    "print('Recognition rate top4: ', test_top4_acc)\n",
    "print('Recognition rate top5: ', test_top5_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test the model with the All dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path where my dataset is stored\n",
    "base_dir3 = '/home/rauly/Documents/Augmentation/Glasses16/Thermal_All16/Testing_Sections'\n",
    "# Directories for test splits\n",
    "test_dir2 = os.path.join(base_dir3, 'test148')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2368 images belonging to 16 classes.\n"
     ]
    }
   ],
   "source": [
    "#Using ImageDataGenerator to read images from directories\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir2,\n",
    "    target_size=(72, 96),\n",
    "    batch_size=148,\n",
    "    color_mode='rgb',\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recognition rate top1:  0.9108952693641186\n",
      "Recognition rate top2:  0.9362331070005894\n",
      "Recognition rate top3:  0.965371623635292\n",
      "Recognition rate top4:  0.9784628376364708\n",
      "Recognition rate top5:  0.9907094538211823\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_top2_acc, test_top3_acc, test_top4_acc, test_top5_acc = model.evaluate_generator(test_generator, steps=16, workers=0, max_queue_size=0)\n",
    "print('Recognition rate top1: ', test_acc)\n",
    "print('Recognition rate top2: ', test_top2_acc)\n",
    "print('Recognition rate top3: ', test_top3_acc)\n",
    "print('Recognition rate top4: ', test_top4_acc)\n",
    "print('Recognition rate top5: ', test_top5_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
