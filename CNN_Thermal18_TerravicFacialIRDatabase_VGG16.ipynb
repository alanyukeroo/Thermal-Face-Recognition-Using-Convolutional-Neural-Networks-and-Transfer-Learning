{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The thermal face recognition process is undertaken using convolutional neural networks (CNN's). \n",
    "More precisely, the system comprises the first 10 layers from the VGG16 architecture, followed by \n",
    "a max-pooling layer, a batch-normalization layer and a classifier (densely connected layer).'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/rauly/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/home/rauly/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "#The VGG16 architecture is imported.\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(72, 96, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 72, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 72, 96, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 72, 96, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 36, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 36, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 36, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 9, 12, 256)        0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 9, 12, 512)        1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 9, 12, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 9, 12, 512)        2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 4, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 4, 6, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 2, 3, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the VGG16 model, only the first 10 layers are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (1,10):\n",
    "    conv_base.layers.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 72, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 72, 96, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 72, 96, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 36, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 36, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 36, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,735,488\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = conv_base.input\n",
    "out =conv_base.layers[-1].output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model2 = Model(inp, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From the first 10 layers, only the last three are set up to allow the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cont = 0\n",
    "for layer in model2.layers:\n",
    "    cont = cont + 1\n",
    "    if (cont >= 8):\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 72, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 72, 96, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 72, 96, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 36, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 36, 48, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 36, 48, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 18, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 18, 24, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 18, 24, 256)       590080    \n",
      "=================================================================\n",
      "Total params: 1,735,488\n",
      "Trainable params: 1,475,328\n",
      "Non-trainable params: 260,160\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Copying images to training, validation, and test directories\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "#Path where my dataset is stored\n",
    "base_dir = '/home/rauly/Documents/Terravic_Thermal_Full/Full_Sections'\n",
    "\n",
    "# Directories for the training, validation and test splits\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Model)              (None, 18, 24, 256)       1735488   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 9, 12, 256)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 9, 12, 256)        1024      \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 27648)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 18)                497682    \n",
      "=================================================================\n",
      "Total params: 2,234,194\n",
      "Trainable params: 1,973,522\n",
      "Non-trainable params: 260,672\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#Here is the proposed model. After the modified VGG16 architecture, a max-pooling layer is append, followed by a \n",
    "#batch-normalization layer, and before the addition of the softmax classifier with 18 categories, the model\n",
    "#is properly flatten.\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(model2)\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(18, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The module metrics is imported in order to show the rank 1-3 recognition rates\n",
    "from keras import metrics\n",
    "import functools\n",
    "from functools import partial\n",
    "top2_acc = functools.partial(metrics.top_k_categorical_accuracy, k=2)\n",
    "top3_acc = functools.partial(metrics.top_k_categorical_accuracy, k=3)\n",
    "top2_acc.__name__ = 'top2_acc'\n",
    "top3_acc.__name__ = 'top3_acc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation stage\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), #Decrease learning rate\n",
    "              metrics=['accuracy',top2_acc, top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1710 images belonging to 18 classes.\n",
      "Found 576 images belonging to 18 classes.\n"
     ]
    }
   ],
   "source": [
    "#Using ImageDataGenerator to read images from directories\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir, # Target directory\n",
    "        target_size=(72, 96), # All images are resized from 240x320 to 72x96\n",
    "        batch_size= 10, \n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical')\n",
    "\n",
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        validation_dir,\n",
    "        target_size=(72, 96),\n",
    "        batch_size=144,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "171/171 [==============================] - 107s 628ms/step - loss: 0.3841 - acc: 0.9082 - top2_acc: 0.9409 - top3_acc: 0.9567 - val_loss: 0.0234 - val_acc: 0.9931 - val_top2_acc: 0.9983 - val_top3_acc: 1.0000\n",
      "Epoch 2/10\n",
      "171/171 [==============================] - 110s 645ms/step - loss: 0.0065 - acc: 0.9977 - top2_acc: 1.0000 - top3_acc: 1.0000 - val_loss: 0.0044 - val_acc: 0.9983 - val_top2_acc: 1.0000 - val_top3_acc: 1.0000\n",
      "Epoch 3/10\n",
      "171/171 [==============================] - 113s 659ms/step - loss: 5.9952e-04 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - val_loss: 0.0052 - val_acc: 0.9983 - val_top2_acc: 1.0000 - val_top3_acc: 1.0000\n",
      "Epoch 4/10\n",
      "171/171 [==============================] - 117s 682ms/step - loss: 7.1040e-05 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - val_loss: 1.9285e-04 - val_acc: 1.0000 - val_top2_acc: 1.0000 - val_top3_acc: 1.0000\n",
      "Epoch 5/10\n",
      "171/171 [==============================] - 111s 647ms/step - loss: 3.5481e-06 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - val_loss: 1.8885e-04 - val_acc: 1.0000 - val_top2_acc: 1.0000 - val_top3_acc: 1.0000\n",
      "Epoch 6/10\n",
      "171/171 [==============================] - 111s 650ms/step - loss: 1.6473e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - val_loss: 2.0922e-06 - val_acc: 1.0000 - val_top2_acc: 1.0000 - val_top3_acc: 1.0000\n",
      "Epoch 7/10\n",
      "171/171 [==============================] - 110s 644ms/step - loss: 1.2095e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - val_loss: 4.1079e-06 - val_acc: 1.0000 - val_top2_acc: 1.0000 - val_top3_acc: 1.0000\n",
      "Epoch 8/10\n",
      "171/171 [==============================] - 111s 648ms/step - loss: 1.2057e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - val_loss: 3.0813e-06 - val_acc: 1.0000 - val_top2_acc: 1.0000 - val_top3_acc: 1.0000\n",
      "Epoch 9/10\n",
      "171/171 [==============================] - 111s 649ms/step - loss: 1.1956e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - val_loss: 1.8667e-06 - val_acc: 1.0000 - val_top2_acc: 1.0000 - val_top3_acc: 1.0000\n",
      "Epoch 10/10\n",
      "171/171 [==============================] - 111s 647ms/step - loss: 1.1938e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000 - val_loss: 1.8923e-06 - val_acc: 1.0000 - val_top2_acc: 1.0000 - val_top3_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Training and validation stages\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=171, #70\n",
    "      epochs= 10,\n",
    "      validation_data=validation_generator,\n",
    "      validation_steps=4,\n",
    "      workers=0,\n",
    "      max_queue_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The proposed model is defined again\n",
    "model = models.Sequential()\n",
    "model.add(model2)\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(18, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compilation stage\n",
    "from keras import optimizers\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), #Decrease learning rate\n",
    "              metrics=['accuracy',top2_acc, top3_acc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "292/292 [==============================] - 171s 584ms/step - loss: 0.1663 - acc: 0.9606 - top2_acc: 0.9740 - top3_acc: 0.9818\n",
      "Epoch 2/4\n",
      "292/292 [==============================] - 165s 565ms/step - loss: 2.6602e-04 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000\n",
      "Epoch 3/4\n",
      "292/292 [==============================] - 161s 553ms/step - loss: 2.6214e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000\n",
      "Epoch 4/4\n",
      "292/292 [==============================] - 160s 549ms/step - loss: 1.2094e-07 - acc: 1.0000 - top2_acc: 1.0000 - top3_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "#Retraining from scratch\n",
    "history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch=292,\n",
    "      epochs=4,\n",
    "      workers=0,\n",
    "      max_queue_size=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1800 images belonging to 18 classes.\n",
      "Recognition rate top1:  1.0\n",
      "Recognition rate top2:  1.0\n",
      "Recognition rate top3:  1.0\n"
     ]
    }
   ],
   "source": [
    "#Test stage\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_dir,\n",
    "        target_size=(72, 96),\n",
    "        batch_size=180,\n",
    "        color_mode='rgb',\n",
    "        class_mode='categorical')\n",
    "\n",
    "test_loss, test_acc, test_top2_acc, test_top3_acc= model.evaluate_generator(test_generator, steps=10, workers=0, max_queue_size=0)\n",
    "print('Recognition rate top1: ', test_acc)\n",
    "print('Recognition rate top2: ', test_top2_acc)\n",
    "print('Recognition rate top3: ', test_top3_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
